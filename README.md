# The-Hindu-News-Article-Classifier

## Installations 

1. [Install Anaconda](https://docs.anaconda.com/anaconda/install/)
2. There are certain dependencies should be installed in your conda environment to work this web app in your local machine.
     - nltk
     - gensim=4.0.1
     - joblib
     - contractions
     - re
     - scikit-learn=0.24.1
3. Need Selenium Chrome WebDriver for scraping the text of the article given its url in web app.
      
## To run web app 
 1. Clone this repo.
 2. Download this [folder](https://drive.google.com/drive/folders/1WPUT9Fk_I7akEMG0pY-F1GpBj62ZETyz?usp=sharing) from Google Drive to get our trained Doc2Vec model for our training dataset. Include all its files in NewsApp directory.
 3. Update the PATH variable present in app.py to installation path location of chromedriver.exe
 4. Run *app.py* in Spyder.
 5. Open [local address](http://127.0.0.1:5000/) in a browser.

## Web App

![](https://github.com/ShamSinha/The-Hindu-News-Article-Classifier/blob/main/Screenshot%20(543).png)
![](https://github.com/ShamSinha/The-Hindu-News-Article-Classifier/blob/main/Screenshot%20(545).png)
![](https://github.com/ShamSinha/The-Hindu-News-Article-Classifier/blob/main/Screenshot%20(546).png)
 
 
 
 
