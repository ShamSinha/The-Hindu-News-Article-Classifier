{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTAWuatXuXR-"
      },
      "source": [
        "!pip install -U scikit-learn==0.24.1\n",
        "!pip install gensim==4.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-USgDcMIXsVw"
      },
      "source": [
        "import pandas as pd\n",
        "import sqlite3"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2_hO7bl4Z7k",
        "outputId": "1984fae4-7a52-4e7b-c3fb-b8b3e1e67ebe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG0Gm2Z84Z-G"
      },
      "source": [
        "def create_connection(db_file):\n",
        "    \"\"\" create a database connection to the SQLite database\n",
        "        specified by the db_file\n",
        "    :param db_file: database file\n",
        "    :return: Connection object or None\n",
        "    \"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "\n",
        "    return conn"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weGXcMArX4r3",
        "outputId": "1d9da6f0-be07-424b-e301-36c5073e6d58"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "### Lemmatization by noun (further preprocessing)\n",
        "def process_n(text):\n",
        "    txt = []\n",
        "    word_tokens = word_tokenize(text) \n",
        "    for w in word_tokens:\n",
        "        txt.append(lemmatizer.lemmatize(w, pos ='n'))\n",
        "    text_p = \" \".join(txt)\n",
        "    return text_p"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crskhdix4aAw",
        "outputId": "fe94f2e5-98cf-4523-f7ad-382017ab86f4"
      },
      "source": [
        "### this code extract article text with its label from sqlite table and store in the list Articles and Class\n",
        "rows = []\n",
        "try:\n",
        "    conn = create_connection('/content/drive/MyDrive/ArticlesDatabaseM.db')\n",
        "    curr = conn.cursor()\n",
        "    query = \"\"\"SELECT article,label FROM articles_tb EXCEPT SELECT article,label FROM articles_tb WHERE label = \"Chennai\" OR label = \"Karnataka\" OR label = \"Kerala\" OR label = \"Tamil Nadu\" OR label = \"Hyderabad\" OR label = \"Mumbai\" OR label = \"Bengaluru\"  \"\"\"\n",
        "    curr.execute(query)\n",
        "    rows = curr.fetchall()\n",
        "\n",
        "    conn.commit()\n",
        "    print(\"Python Variables successfully selected from articles_link_tb \" )\n",
        "\n",
        "    curr.close()\n",
        "\n",
        "except sqlite3.Error as error:\n",
        "    print(\"Failed to select Python variable from sqlite table\", error)\n",
        "finally:\n",
        "      conn.close()\n",
        "      print(\"The SQLite connection is closed\")\n",
        "\n",
        "Articles = []\n",
        "Class = []\n",
        "for row in rows:\n",
        "    Articles.append(process_n(row[0]))\n",
        "    Class.append(row[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python Variables successfully selected from articles_link_tb \n",
            "The SQLite connection is closed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7quGpsd4aDI",
        "outputId": "61a9800a-5c53-44ea-9cfb-afa3f1a5d809"
      },
      "source": [
        "### creating pandas dataframe from the extracted data\n",
        "data = {'Article':Articles,\n",
        "\t\t'Class':Class}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the output.\n",
        "print(df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 Article          Class\n",
            "0                                                                 Books\n",
            "1                                                               Cricket\n",
            "2                                                             Education\n",
            "3                                                             Elections\n",
            "4                                                         Entertainment\n",
            "...                                                  ...            ...\n",
            "48958  zumba bring back gate hell balance equation li...        Society\n",
            "48959  çelebi aviation hold grind handle licence hyde...       Business\n",
            "48960  école intuit lab open application école intuit...      Education\n",
            "48961  ït plan shoot say agasthya karthikeyan photogr...   Life & Style\n",
            "48962  škoda auto india unveil refresh superb range n...       Business\n",
            "\n",
            "[48963 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s00vPvfe4aFE"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "data['Category_Class']= label_encoder.fit_transform(data['Class'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "GROv7rqp5V-6",
        "outputId": "7d9c6173-8cdf-410d-e7e2-5ebe943669b0"
      },
      "source": [
        "Thehindu = pd.DataFrame()\n",
        "Thehindu['Article'] = data['Article']\n",
        "Thehindu['Class'] = data['Class']\n",
        "Thehindu['Category_Class'] = data['Category_Class']\n",
        "print(Thehindu['Class'].value_counts())\n",
        "Thehindu.sample(5, random_state=0)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Life & Style     4641\n",
            "Business         4434\n",
            "Sci-Tech         3772\n",
            "Entertainment    3723\n",
            "Other Sports     3664\n",
            "Elections        3593\n",
            "Society          3591\n",
            "Tennis           2915\n",
            "Education        2743\n",
            "International    2726\n",
            "National         2520\n",
            "Football         2491\n",
            "Cricket          2437\n",
            "Books            1944\n",
            "Health           1905\n",
            "Environment      1864\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Class</th>\n",
              "      <th>Category_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18336</th>\n",
              "      <td>high voltage entertainment former national cha...</td>\n",
              "      <td>Tennis</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36003</th>\n",
              "      <td>russian track federation president step aside ...</td>\n",
              "      <td>Other Sports</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9336</th>\n",
              "      <td>dance prince lady good catch eye horse exercis...</td>\n",
              "      <td>Other Sports</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11325</th>\n",
              "      <td>duet hindustani classical music gimmick case e...</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20536</th>\n",
              "      <td>indian tourist plan vacation southeast asia fa...</td>\n",
              "      <td>Life &amp; Style</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Article  ... Category_Class\n",
              "18336  high voltage entertainment former national cha...  ...             15\n",
              "36003  russian track federation president step aside ...  ...             12\n",
              "9336   dance prince lady good catch eye horse exercis...  ...             12\n",
              "11325  duet hindustani classical music gimmick case e...  ...              5\n",
              "20536  indian tourist plan vacation southeast asia fa...  ...             10\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36nlsGfLZCky",
        "outputId": "b3bc9598-95c3-4b12-a574-03af31b109fc"
      },
      "source": [
        "class_num = []\n",
        "for x in range(16):\n",
        "  class_num.append(x)\n",
        "\n",
        "class_list = list(label_encoder.inverse_transform(class_num))\n",
        "print(class_list)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Books', 'Business', 'Cricket', 'Education', 'Elections', 'Entertainment', 'Environment', 'Football', 'Health', 'International', 'Life & Style', 'National', 'Other Sports', 'Sci-Tech', 'Society', 'Tennis']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwV1t6gTwnPS",
        "outputId": "6bcf1321-10a7-4417-eb03-0a25761ce0f6"
      },
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8ogr1WI5ti_"
      },
      "source": [
        "def label_sentences(corpus, label_type):\n",
        "    \"\"\"\n",
        "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
        "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
        "    a dummy index of the post.\n",
        "    \"\"\"\n",
        "    labeled = []\n",
        "\n",
        "    for i, v in enumerate(corpus):\n",
        "        label = label_type + '_' + str(i)\n",
        "        labeled.append(TaggedDocument(v.split(), [label]))\n",
        "    \n",
        "    return labeled\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Thehindu.Article, Thehindu.Category_Class, random_state=80, test_size=0.25)\n",
        "\n",
        "X_train = label_sentences(X_train, 'Train')\n",
        "X_test = label_sentences(X_test, 'Test')\n",
        "all_data = X_train + X_test"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFGgx5oM_ilJ",
        "outputId": "5c208262-7e89-46cb-aaec-9cde6c333ca3"
      },
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative = 5 , min_count= 2 , alpha=0.065, min_alpha=0.065, workers = 16)\n",
        "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
        "\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 48963/48963 [00:00<00:00, 2383040.99it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2523788.36it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2172791.21it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2324587.77it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2462359.50it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2772028.17it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2382626.28it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2364847.33it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2315910.81it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2277311.87it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2440645.88it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2586925.99it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2468189.49it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2615690.48it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2407372.28it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2487924.24it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2364629.49it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2413681.85it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2261388.19it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2235029.73it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2517384.46it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2286337.65it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2732634.85it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2255848.80it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2372825.88it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2653783.72it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2370963.05it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2525805.98it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2199435.66it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2395605.85it/s]\n",
            "100%|██████████| 48963/48963 [00:00<00:00, 2586991.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01LZMvEdDKlf"
      },
      "source": [
        "import numpy as np\n",
        "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
        "    \"\"\"\n",
        "    Get vectors from trained doc2vec model\n",
        "    :param doc2vec_model: Trained Doc2Vec model\n",
        "    :param corpus_size: Size of the data\n",
        "    :param vectors_size: Size of the embedding vectors\n",
        "    :param vectors_type: Training or Testing vectors\n",
        "    :return: list of vectors\n",
        "    \"\"\"\n",
        "    vectors = np.zeros((corpus_size, vectors_size))\n",
        "    for i in range(0, corpus_size):\n",
        "        prefix = vectors_type + '_' + str(i)\n",
        "        vectors[i] = model.dv[prefix]\n",
        "    return vectors\n",
        "    \n",
        "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
        "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biR9H9mNRye0",
        "outputId": "e15e8f06-3465-4914-9abc-6aba4fa1bf31"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf_neural = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(250,150,50), random_state=1 , verbose = True, activation = 'relu')\n",
        "\n",
        "clf_neural = clf_neural.fit(train_vectors_dbow, y_train)\n",
        "model_prediction_neural = clf_neural.predict(test_vectors_dbow)\n",
        "model_train_pred_neural = clf_neural.predict(train_vectors_dbow)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.04341484\n",
            "Iteration 2, loss = 0.52079026\n",
            "Iteration 3, loss = 0.45382889\n",
            "Iteration 4, loss = 0.40325121\n",
            "Iteration 5, loss = 0.35249930\n",
            "Iteration 6, loss = 0.30145523\n",
            "Iteration 7, loss = 0.25089317\n",
            "Iteration 8, loss = 0.19919706\n",
            "Iteration 9, loss = 0.15421977\n",
            "Iteration 10, loss = 0.11180061\n",
            "Iteration 11, loss = 0.07367363\n",
            "Iteration 12, loss = 0.04811834\n",
            "Iteration 13, loss = 0.03262227\n",
            "Iteration 14, loss = 0.01884664\n",
            "Iteration 15, loss = 0.01153761\n",
            "Iteration 16, loss = 0.00738977\n",
            "Iteration 17, loss = 0.00639589\n",
            "Iteration 18, loss = 0.00540695\n",
            "Iteration 19, loss = 0.00545559\n",
            "Iteration 20, loss = 0.00436054\n",
            "Iteration 21, loss = 0.00407826\n",
            "Iteration 22, loss = 0.00354813\n",
            "Iteration 23, loss = 0.00347560\n",
            "Iteration 24, loss = 0.12849201\n",
            "Iteration 25, loss = 0.09492353\n",
            "Iteration 26, loss = 0.03165399\n",
            "Iteration 27, loss = 0.00948648\n",
            "Iteration 28, loss = 0.00393600\n",
            "Iteration 29, loss = 0.00234713\n",
            "Iteration 30, loss = 0.00162625\n",
            "Iteration 31, loss = 0.00134054\n",
            "Iteration 32, loss = 0.00120235\n",
            "Iteration 33, loss = 0.00110964\n",
            "Iteration 34, loss = 0.00103829\n",
            "Iteration 35, loss = 0.00098130\n",
            "Iteration 36, loss = 0.00093465\n",
            "Iteration 37, loss = 0.00089820\n",
            "Iteration 38, loss = 0.00086256\n",
            "Iteration 39, loss = 0.00083581\n",
            "Iteration 40, loss = 0.00081009\n",
            "Iteration 41, loss = 0.00078696\n",
            "Iteration 42, loss = 0.00077119\n",
            "Iteration 43, loss = 0.00075700\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGBrOCi2zN0b",
        "outputId": "0a1bb82e-0132-4d05-ea7a-b06664b98fc7"
      },
      "source": [
        "print('accuracy on training set %s' % accuracy_score(model_train_pred_neural, y_train))\n",
        "print('accuracy on test set %s' % accuracy_score(model_prediction_neural, y_test))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on training set 0.9998093785741518\n",
            "accuracy on test set 0.813495629442039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31ebFISYa_Q",
        "outputId": "f513a4ed-8ed7-4831-fb70-348a25e44cd6"
      },
      "source": [
        "print(classification_report(y_test, model_prediction_neural, target_names= class_list))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Books       0.76      0.79      0.77       490\n",
            "     Business       0.87      0.88      0.88      1109\n",
            "      Cricket       0.95      0.96      0.95       610\n",
            "    Education       0.79      0.79      0.79       671\n",
            "    Elections       0.90      0.94      0.92       919\n",
            "Entertainment       0.79      0.78      0.78       919\n",
            "  Environment       0.71      0.72      0.71       492\n",
            "     Football       0.96      0.96      0.96       614\n",
            "       Health       0.67      0.70      0.69       460\n",
            "International       0.82      0.80      0.81       711\n",
            " Life & Style       0.70      0.73      0.71      1129\n",
            "     National       0.69      0.65      0.67       624\n",
            " Other Sports       0.94      0.95      0.94       912\n",
            "     Sci-Tech       0.77      0.76      0.76       992\n",
            "      Society       0.67      0.61      0.64       905\n",
            "       Tennis       0.97      0.98      0.98       684\n",
            "\n",
            "     accuracy                           0.81     12241\n",
            "    macro avg       0.81      0.81      0.81     12241\n",
            " weighted avg       0.81      0.81      0.81     12241\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEUSdI-RhKEJ"
      },
      "source": [
        "from gensim.test.utils import get_tmpfile\n",
        "\n",
        "fname = get_tmpfile(\"/content/drive/MyDrive/doc2vec_model2\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLjzXypIwX6j"
      },
      "source": [
        "model_dbow.save(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhc1rULVwTiH"
      },
      "source": [
        "model_dbow = Doc2Vec.load(fname)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qErr8bHcimhw"
      },
      "source": [
        "from joblib import dump, load\n",
        "dump(clf_neural, '/content/drive/MyDrive/clf_neural_new2.joblib') "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDlOo9olpyJH",
        "outputId": "9465af24-8d19-4f24-fa61-6c97ae62d1d9"
      },
      "source": [
        "clf2 = load('/content/drive/MyDrive/clf_neural_new2.joblib') \n",
        "model_prediction_neural = clf2.predict(test_vectors_dbow)\n",
        "model_train_pred_neural = clf2.predict(train_vectors_dbow)\n",
        "print('accuracy on training set %s' % accuracy_score(model_train_pred_neural, y_train))\n",
        "print('accuracy on test set %s' % accuracy_score(model_prediction_neural, y_test))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on training set 0.9998093785741518\n",
            "accuracy on test set 0.813495629442039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc9dheHwVKDo"
      },
      "source": [
        "text = 'indias export rise billion june account healthy growth shipments sectors engineer gems jewellery petroleum products accord preliminary data commerce ministry import rise billion period data show export sectors engineer gems jewellery petroleum products record healthy growth rat export grow billion first week month billion second week month accord data export april may fiscal year jump billion billion period last year'"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fwx_pQu3YhAu",
        "outputId": "26254ef1-bb80-4bc9-9789-d09782543cce"
      },
      "source": [
        "word_tokens = word_tokenize(text) \n",
        "vector = model_dbow.infer_vector(word_tokens)\n",
        "vector = vector.reshape(1, -1)\n",
        "model_prediction = clf_neural.predict(vector)\n",
        "class_list[model_prediction[0]]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Business'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}